{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose Estimation Related to Emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the iPython Notebook, it is important to install all necessary packages. To do that, in terminal type the command <code>pip install -r requirements.txt</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deniskrylov/Developer/PosEmotion/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "from tools.detector import detect_poses\n",
    "from tools.extractor import Extractor\n",
    "from tools.metrics import label_probabilities\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before operating with data, it's important to see how the data looks like. For that purpose, let's convert <code>annotation.csv</code> file to pandas Dataframe. As we can see below, the Dataframe has the following structure:\n",
    "\n",
    "- Video Tag → The video identification present in YouTube. Use it to retrieve the source video. \n",
    "In this version of the dataset, the videos are present in the \"/Videos\" folder.\n",
    "- Clip Id → Id for each clip from a source video. This identification is unique within a source video. \n",
    "For a certain “Video Tag” with an “Clip Id”, the “Person Id” will be unique to a certain person. \n",
    "- Labels → An arrays of arrays containing the labels given by each annotator of the dataset.\n",
    "- Frame Number → The frame that was used for that annotation\n",
    "- X → Starting position of the bounding box in the x-axis\n",
    "- Y → Starting position of the bounding box in the y-axis\n",
    "- Width → % of the width of the video used as offset for “X”\n",
    "- Height → % of the height of the video used as offset for “Y”\n",
    "- Person Id → Integer to identify a certain person for clips with the same “Video Tag” and “Clip Id”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Tag</th>\n",
       "      <th>Clip Id</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Frame Number</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Person Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aJKL0ahn1Dk</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Happy'], ['Happy'], ['Happy']]</td>\n",
       "      <td>19532</td>\n",
       "      <td>41.965200</td>\n",
       "      <td>4.873195</td>\n",
       "      <td>44.216991</td>\n",
       "      <td>94.802684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aJKL0ahn1Dk</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Happy'], ['Happy'], ['Happy']]</td>\n",
       "      <td>19538</td>\n",
       "      <td>41.564836</td>\n",
       "      <td>4.874640</td>\n",
       "      <td>44.216991</td>\n",
       "      <td>94.802684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aJKL0ahn1Dk</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Happy'], ['Happy'], ['Happy']]</td>\n",
       "      <td>19544</td>\n",
       "      <td>41.164472</td>\n",
       "      <td>4.876086</td>\n",
       "      <td>44.216991</td>\n",
       "      <td>94.802684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aJKL0ahn1Dk</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Happy'], ['Happy'], ['Happy']]</td>\n",
       "      <td>19550</td>\n",
       "      <td>40.764108</td>\n",
       "      <td>4.877532</td>\n",
       "      <td>44.216991</td>\n",
       "      <td>94.802684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aJKL0ahn1Dk</td>\n",
       "      <td>1</td>\n",
       "      <td>[['Happy'], ['Happy'], ['Happy']]</td>\n",
       "      <td>19556</td>\n",
       "      <td>39.646728</td>\n",
       "      <td>5.014136</td>\n",
       "      <td>44.216991</td>\n",
       "      <td>94.802684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Video Tag  Clip Id                             Labels  Frame Number  \\\n",
       "0  aJKL0ahn1Dk        1  [['Happy'], ['Happy'], ['Happy']]         19532   \n",
       "1  aJKL0ahn1Dk        1  [['Happy'], ['Happy'], ['Happy']]         19538   \n",
       "2  aJKL0ahn1Dk        1  [['Happy'], ['Happy'], ['Happy']]         19544   \n",
       "3  aJKL0ahn1Dk        1  [['Happy'], ['Happy'], ['Happy']]         19550   \n",
       "4  aJKL0ahn1Dk        1  [['Happy'], ['Happy'], ['Happy']]         19556   \n",
       "\n",
       "           X         Y      Width     Height  Person Id  \n",
       "0  41.965200  4.873195  44.216991  94.802684          0  \n",
       "1  41.564836  4.874640  44.216991  94.802684          0  \n",
       "2  41.164472  4.876086  44.216991  94.802684          0  \n",
       "3  40.764108  4.877532  44.216991  94.802684          0  \n",
       "4  39.646728  5.014136  44.216991  94.802684          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"assets/annotations/annotations.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each combination of <code>Video Tag</code>, <code>Clip Id</code> and <code>Person Id</code> represents a unique emotion related to a person. Therefore, we can split these emotions into segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of segments: 629\n",
      "First 5 segments: [(0, 27), (28, 39), (40, 51), (52, 69), (70, 77)]\n"
     ]
    }
   ],
   "source": [
    "extractor = Extractor(\n",
    "    \"/Users/deniskrylov/Developer/PosEmotion/assets/annotations/annotations.csv\",\n",
    "    \"/Users/deniskrylov/Developer/PosEmotion/assets/videos\",\n",
    "    \"/Users/deniskrylov/Developer/PosEmotion/assets/frames\"\n",
    ")\n",
    "\n",
    "# Uncomment the line below to extract frames from the videos\n",
    "# extractor.extract_frames()\n",
    "\n",
    "# Extracting the segments from the CSV file \n",
    "# (each segment represents a unique person in the fragment of video)\n",
    "segments = extractor.extract_segments()\n",
    "print(\"Number of segments:\", len(segments))\n",
    "print(\"First 5 segments:\", segments[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before pose detection, we need to convert our dataset in such a way, that the array of <code>Labels</code> column will be converted to multiple columns, where each column represents a probability of a particular emotion, calculated as $i/n$, where $i$ is an emotion label and $n$ is a total number of emotions that were detected by different annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Tag</th>\n",
       "      <th>Clip Id</th>\n",
       "      <th>Frame Number</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Person Id</th>\n",
       "      <th>Happy</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Anger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aJKL0ahn1Dk</td>\n",
       "      <td>1</td>\n",
       "      <td>19532</td>\n",
       "      <td>41.965200</td>\n",
       "      <td>4.873195</td>\n",
       "      <td>44.216991</td>\n",
       "      <td>94.802684</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aJKL0ahn1Dk</td>\n",
       "      <td>1</td>\n",
       "      <td>19538</td>\n",
       "      <td>41.564836</td>\n",
       "      <td>4.874640</td>\n",
       "      <td>44.216991</td>\n",
       "      <td>94.802684</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aJKL0ahn1Dk</td>\n",
       "      <td>1</td>\n",
       "      <td>19544</td>\n",
       "      <td>41.164472</td>\n",
       "      <td>4.876086</td>\n",
       "      <td>44.216991</td>\n",
       "      <td>94.802684</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aJKL0ahn1Dk</td>\n",
       "      <td>1</td>\n",
       "      <td>19550</td>\n",
       "      <td>40.764108</td>\n",
       "      <td>4.877532</td>\n",
       "      <td>44.216991</td>\n",
       "      <td>94.802684</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aJKL0ahn1Dk</td>\n",
       "      <td>1</td>\n",
       "      <td>19556</td>\n",
       "      <td>39.646728</td>\n",
       "      <td>5.014136</td>\n",
       "      <td>44.216991</td>\n",
       "      <td>94.802684</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Video Tag  Clip Id  Frame Number          X         Y      Width  \\\n",
       "0  aJKL0ahn1Dk        1         19532  41.965200  4.873195  44.216991   \n",
       "1  aJKL0ahn1Dk        1         19538  41.564836  4.874640  44.216991   \n",
       "2  aJKL0ahn1Dk        1         19544  41.164472  4.876086  44.216991   \n",
       "3  aJKL0ahn1Dk        1         19550  40.764108  4.877532  44.216991   \n",
       "4  aJKL0ahn1Dk        1         19556  39.646728  5.014136  44.216991   \n",
       "\n",
       "      Height  Person Id  Happy  Sad  Fear  Neutral  Surprise  Disgust  Anger  \n",
       "0  94.802684          0    1.0  0.0   0.0      0.0       0.0      0.0    0.0  \n",
       "1  94.802684          0    1.0  0.0   0.0      0.0       0.0      0.0    0.0  \n",
       "2  94.802684          0    1.0  0.0   0.0      0.0       0.0      0.0    0.0  \n",
       "3  94.802684          0    1.0  0.0   0.0      0.0       0.0      0.0    0.0  \n",
       "4  94.802684          0    1.0  0.0   0.0      0.0       0.0      0.0    0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = label_probabilities(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Key Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract keypoints, different approaches will be used such as YOLO-Pose, DeepPose and OpenPose. For each of the approaches, a different dataframe will be created with coordinates of keypoints.\n",
    "\n",
    "- For each frame, a person will be detected (using ground truth) and cut out of the frame.\n",
    "- After for each frame pose detection algorithm will be applied.\n",
    "- At the end, csv file with keypoints will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each row get X, Y, Width, Height\n",
    "# create a cropped_image = image[y:y+h, x:x+w]\n",
    "# use this cropped image to detect poses\n",
    "# get the pose keypoints\n",
    "# add them to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YOLO-Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_0.jpg: 768x1280 1 person, 1097.3ms\n",
      "Speed: 2.4ms preprocess, 1097.3ms inference, 245.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 1/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_1.jpg: 768x1280 1 person, 1045.9ms\n",
      "Speed: 1.7ms preprocess, 1045.9ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 2/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_2.jpg: 768x1280 1 person, 1036.3ms\n",
      "Speed: 1.6ms preprocess, 1036.3ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 3/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_3.jpg: 768x1280 1 person, 1047.6ms\n",
      "Speed: 1.7ms preprocess, 1047.6ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 4/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_4.jpg: 768x1280 1 person, 1020.4ms\n",
      "Speed: 1.8ms preprocess, 1020.4ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 5/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_5.jpg: 768x1280 1 person, 1010.3ms\n",
      "Speed: 1.8ms preprocess, 1010.3ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 6/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_6.jpg: 768x1280 1 person, 1026.4ms\n",
      "Speed: 1.8ms preprocess, 1026.4ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 7/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_7.jpg: 768x1280 1 person, 1008.6ms\n",
      "Speed: 1.6ms preprocess, 1008.6ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 8/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_8.jpg: 768x1280 1 person, 1021.1ms\n",
      "Speed: 1.7ms preprocess, 1021.1ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 9/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_9.jpg: 768x1280 1 person, 1013.1ms\n",
      "Speed: 1.6ms preprocess, 1013.1ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 10/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_10.jpg: 768x1280 1 person, 1011.7ms\n",
      "Speed: 2.0ms preprocess, 1011.7ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 11/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_11.jpg: 768x1280 1 person, 1010.6ms\n",
      "Speed: 1.7ms preprocess, 1010.6ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 12/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_12.jpg: 768x1280 1 person, 1015.7ms\n",
      "Speed: 1.9ms preprocess, 1015.7ms inference, 0.8ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 13/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_13.jpg: 768x1280 1 person, 1010.3ms\n",
      "Speed: 1.7ms preprocess, 1010.3ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 14/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_14.jpg: 768x1280 1 person, 1019.1ms\n",
      "Speed: 1.7ms preprocess, 1019.1ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 15/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_15.jpg: 768x1280 1 person, 1046.2ms\n",
      "Speed: 1.6ms preprocess, 1046.2ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 16/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_16.jpg: 768x1280 1 person, 1016.9ms\n",
      "Speed: 1.6ms preprocess, 1016.9ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 17/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_17.jpg: 768x1280 1 person, 1024.6ms\n",
      "Speed: 1.6ms preprocess, 1024.6ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 18/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_18.jpg: 768x1280 1 person, 1070.8ms\n",
      "Speed: 1.5ms preprocess, 1070.8ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 19/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_19.jpg: 768x1280 1 person, 1045.2ms\n",
      "Speed: 2.0ms preprocess, 1045.2ms inference, 1.0ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 20/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_20.jpg: 768x1280 1 person, 1040.9ms\n",
      "Speed: 1.8ms preprocess, 1040.9ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 21/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_21.jpg: 768x1280 1 person, 1029.9ms\n",
      "Speed: 1.9ms preprocess, 1029.9ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 22/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_22.jpg: 768x1280 1 person, 1023.9ms\n",
      "Speed: 1.5ms preprocess, 1023.9ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 23/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_23.jpg: 768x1280 1 person, 1022.6ms\n",
      "Speed: 1.7ms preprocess, 1022.6ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 24/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_24.jpg: 768x1280 1 person, 1078.1ms\n",
      "Speed: 1.5ms preprocess, 1078.1ms inference, 0.8ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 25/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_25.jpg: 768x1280 1 person, 1077.1ms\n",
      "Speed: 1.6ms preprocess, 1077.1ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 26/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_26.jpg: 768x1280 1 person, 1091.9ms\n",
      "Speed: 1.6ms preprocess, 1091.9ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 27/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_27.jpg: 768x1280 1 person, 1021.8ms\n",
      "Speed: 1.6ms preprocess, 1021.8ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 28/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_28.jpg: 768x1280 1 person, 1016.8ms\n",
      "Speed: 1.5ms preprocess, 1016.8ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 29/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_29.jpg: 768x1280 1 person, 1011.3ms\n",
      "Speed: 1.6ms preprocess, 1011.3ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 30/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_30.jpg: 768x1280 1 person, 1014.4ms\n",
      "Speed: 1.7ms preprocess, 1014.4ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 31/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_31.jpg: 768x1280 1 person, 1012.8ms\n",
      "Speed: 1.7ms preprocess, 1012.8ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 32/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_32.jpg: 768x1280 1 person, 1012.8ms\n",
      "Speed: 1.7ms preprocess, 1012.8ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 33/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_33.jpg: 768x1280 1 person, 1011.8ms\n",
      "Speed: 1.5ms preprocess, 1011.8ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 34/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_34.jpg: 768x1280 1 person, 1021.1ms\n",
      "Speed: 1.8ms preprocess, 1021.1ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 35/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_35.jpg: 768x1280 1 person, 1014.4ms\n",
      "Speed: 1.7ms preprocess, 1014.4ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 36/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_36.jpg: 768x1280 1 person, 1013.5ms\n",
      "Speed: 1.8ms preprocess, 1013.5ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 37/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_37.jpg: 768x1280 1 person, 1022.6ms\n",
      "Speed: 1.8ms preprocess, 1022.6ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 38/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_38.jpg: 768x1280 1 person, 1009.9ms\n",
      "Speed: 1.6ms preprocess, 1009.9ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 39/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_39.jpg: 768x1280 1 person, 1011.3ms\n",
      "Speed: 1.9ms preprocess, 1011.3ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 40/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_40.jpg: 768x1280 1 person, 1021.9ms\n",
      "Speed: 1.7ms preprocess, 1021.9ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 41/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_41.jpg: 768x1280 1 person, 1008.7ms\n",
      "Speed: 1.6ms preprocess, 1008.7ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 42/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_42.jpg: 768x1280 1 person, 1007.6ms\n",
      "Speed: 1.6ms preprocess, 1007.6ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 43/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_43.jpg: 768x1280 1 person, 1015.1ms\n",
      "Speed: 1.9ms preprocess, 1015.1ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 44/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_44.jpg: 768x1280 1 person, 1013.8ms\n",
      "Speed: 1.9ms preprocess, 1013.8ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 45/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_45.jpg: 768x1280 1 person, 1010.9ms\n",
      "Speed: 1.6ms preprocess, 1010.9ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 46/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_46.jpg: 768x1280 1 person, 1009.2ms\n",
      "Speed: 1.5ms preprocess, 1009.2ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 47/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_47.jpg: 768x1280 1 person, 1012.4ms\n",
      "Speed: 1.9ms preprocess, 1012.4ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 48/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_48.jpg: 768x1280 1 person, 1012.0ms\n",
      "Speed: 1.6ms preprocess, 1012.0ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 49/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_49.jpg: 768x1280 1 person, 1040.7ms\n",
      "Speed: 1.8ms preprocess, 1040.7ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 50/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_50.jpg: 768x1280 1 person, 1014.7ms\n",
      "Speed: 1.7ms preprocess, 1014.7ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 51/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_51.jpg: 768x1280 1 person, 1046.0ms\n",
      "Speed: 1.6ms preprocess, 1046.0ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 52/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_52.jpg: 768x1280 1 person, 1022.4ms\n",
      "Speed: 1.7ms preprocess, 1022.4ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 53/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_53.jpg: 768x1280 1 person, 1011.3ms\n",
      "Speed: 1.6ms preprocess, 1011.3ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 54/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_54.jpg: 768x1280 1 person, 1016.2ms\n",
      "Speed: 1.5ms preprocess, 1016.2ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 55/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_55.jpg: 768x1280 1 person, 1014.6ms\n",
      "Speed: 1.7ms preprocess, 1014.6ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 56/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_56.jpg: 768x1280 1 person, 1012.1ms\n",
      "Speed: 1.7ms preprocess, 1012.1ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 57/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_57.jpg: 768x1280 1 person, 1031.4ms\n",
      "Speed: 1.9ms preprocess, 1031.4ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 58/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_58.jpg: 768x1280 1 person, 1012.3ms\n",
      "Speed: 1.8ms preprocess, 1012.3ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 59/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_59.jpg: 768x1280 1 person, 1013.7ms\n",
      "Speed: 1.7ms preprocess, 1013.7ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 60/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_60.jpg: 768x1280 1 person, 1016.1ms\n",
      "Speed: 1.8ms preprocess, 1016.1ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 61/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_61.jpg: 768x1280 1 person, 1033.4ms\n",
      "Speed: 1.7ms preprocess, 1033.4ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 62/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_62.jpg: 768x1280 1 person, 1015.1ms\n",
      "Speed: 1.6ms preprocess, 1015.1ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 63/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_63.jpg: 768x1280 1 person, 1017.8ms\n",
      "Speed: 1.8ms preprocess, 1017.8ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 64/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_64.jpg: 768x1280 1 person, 1029.0ms\n",
      "Speed: 1.5ms preprocess, 1029.0ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 65/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_65.jpg: 768x1280 1 person, 1036.7ms\n",
      "Speed: 1.7ms preprocess, 1036.7ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 66/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_66.jpg: 768x1280 1 person, 1021.7ms\n",
      "Speed: 1.5ms preprocess, 1021.7ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 67/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_67.jpg: 768x1280 1 person, 1021.4ms\n",
      "Speed: 1.6ms preprocess, 1021.4ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 68/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_68.jpg: 768x1280 1 person, 1025.5ms\n",
      "Speed: 1.7ms preprocess, 1025.5ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 69/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_69.jpg: 768x1280 1 person, 1014.8ms\n",
      "Speed: 1.7ms preprocess, 1014.8ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 70/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_70.jpg: 768x1280 1 person, 1017.4ms\n",
      "Speed: 1.8ms preprocess, 1017.4ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 71/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_71.jpg: 768x1280 1 person, 1041.7ms\n",
      "Speed: 1.7ms preprocess, 1041.7ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 72/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_72.jpg: 768x1280 1 person, 1059.0ms\n",
      "Speed: 1.9ms preprocess, 1059.0ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 73/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_73.jpg: 768x1280 1 person, 1028.0ms\n",
      "Speed: 1.9ms preprocess, 1028.0ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 74/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_74.jpg: 768x1280 1 person, 1042.3ms\n",
      "Speed: 1.7ms preprocess, 1042.3ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 75/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_75.jpg: 768x1280 1 person, 1013.9ms\n",
      "Speed: 1.4ms preprocess, 1013.9ms inference, 0.8ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 76/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_76.jpg: 768x1280 1 person, 1014.1ms\n",
      "Speed: 1.7ms preprocess, 1014.1ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 77/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_77.jpg: 768x1280 1 person, 1009.5ms\n",
      "Speed: 1.6ms preprocess, 1009.5ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 78/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_78.jpg: 768x1280 1 person, 1018.1ms\n",
      "Speed: 1.9ms preprocess, 1018.1ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 79/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_79.jpg: 768x1280 1 person, 1014.7ms\n",
      "Speed: 1.5ms preprocess, 1014.7ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 80/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_80.jpg: 768x1280 1 person, 1012.0ms\n",
      "Speed: 2.0ms preprocess, 1012.0ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 81/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_81.jpg: 768x1280 1 person, 1014.7ms\n",
      "Speed: 1.5ms preprocess, 1014.7ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 82/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_82.jpg: 768x1280 1 person, 1018.8ms\n",
      "Speed: 1.6ms preprocess, 1018.8ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 83/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_83.jpg: 768x1280 1 person, 1008.2ms\n",
      "Speed: 1.7ms preprocess, 1008.2ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 84/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_84.jpg: 768x1280 1 person, 1009.8ms\n",
      "Speed: 1.8ms preprocess, 1009.8ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 85/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_85.jpg: 768x1280 1 person, 1019.3ms\n",
      "Speed: 1.6ms preprocess, 1019.3ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 86/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_86.jpg: 768x1280 1 person, 1012.7ms\n",
      "Speed: 1.5ms preprocess, 1012.7ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 87/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_87.jpg: 768x1280 1 person, 1050.0ms\n",
      "Speed: 2.1ms preprocess, 1050.0ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 88/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_88.jpg: 768x1280 1 person, 1091.5ms\n",
      "Speed: 1.7ms preprocess, 1091.5ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 89/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_89.jpg: 768x1280 1 person, 1148.8ms\n",
      "Speed: 1.9ms preprocess, 1148.8ms inference, 0.9ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 90/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_90.jpg: 768x1280 2 persons, 1044.2ms\n",
      "Speed: 2.0ms preprocess, 1044.2ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 91/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_91.jpg: 768x1280 1 person, 1055.2ms\n",
      "Speed: 1.9ms preprocess, 1055.2ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 92/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_92.jpg: 768x1280 2 persons, 1049.3ms\n",
      "Speed: 1.6ms preprocess, 1049.3ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 93/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_93.jpg: 768x1280 3 persons, 1037.5ms\n",
      "Speed: 1.5ms preprocess, 1037.5ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 94/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_94.jpg: 768x1280 2 persons, 1030.8ms\n",
      "Speed: 1.6ms preprocess, 1030.8ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 95/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_95.jpg: 768x1280 2 persons, 1044.8ms\n",
      "Speed: 1.6ms preprocess, 1044.8ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 96/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_96.jpg: 768x1280 3 persons, 1058.5ms\n",
      "Speed: 1.8ms preprocess, 1058.5ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 97/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_97.jpg: 768x1280 3 persons, 1067.1ms\n",
      "Speed: 1.9ms preprocess, 1067.1ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 98/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_98.jpg: 768x1280 3 persons, 1038.4ms\n",
      "Speed: 1.7ms preprocess, 1038.4ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 99/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_99.jpg: 768x1280 3 persons, 1061.7ms\n",
      "Speed: 2.0ms preprocess, 1061.7ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 100/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_100.jpg: 768x1280 3 persons, 1038.3ms\n",
      "Speed: 1.7ms preprocess, 1038.3ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 101/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_101.jpg: 768x1280 3 persons, 1047.6ms\n",
      "Speed: 1.7ms preprocess, 1047.6ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 102/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_102.jpg: 768x1280 2 persons, 1075.4ms\n",
      "Speed: 1.7ms preprocess, 1075.4ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 103/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_103.jpg: 768x1280 2 persons, 1094.6ms\n",
      "Speed: 1.8ms preprocess, 1094.6ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 104/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_104.jpg: 768x1280 1 person, 1094.2ms\n",
      "Speed: 1.8ms preprocess, 1094.2ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 105/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_105.jpg: 768x1280 1 person, 1046.6ms\n",
      "Speed: 1.8ms preprocess, 1046.6ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 106/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_106.jpg: 768x1280 1 person, 1066.7ms\n",
      "Speed: 1.8ms preprocess, 1066.7ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 107/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_107.jpg: 768x1280 1 person, 1070.5ms\n",
      "Speed: 1.7ms preprocess, 1070.5ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 108/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_108.jpg: 768x1280 2 persons, 1039.4ms\n",
      "Speed: 1.6ms preprocess, 1039.4ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 109/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_109.jpg: 768x1280 2 persons, 1028.8ms\n",
      "Speed: 1.5ms preprocess, 1028.8ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 110/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_110.jpg: 768x1280 2 persons, 1035.1ms\n",
      "Speed: 1.7ms preprocess, 1035.1ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 111/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_111.jpg: 768x1280 2 persons, 1026.4ms\n",
      "Speed: 1.8ms preprocess, 1026.4ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 112/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_112.jpg: 768x1280 2 persons, 1041.8ms\n",
      "Speed: 1.6ms preprocess, 1041.8ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 113/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_113.jpg: 768x1280 2 persons, 1057.1ms\n",
      "Speed: 1.8ms preprocess, 1057.1ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 114/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_114.jpg: 768x1280 2 persons, 1041.2ms\n",
      "Speed: 1.8ms preprocess, 1041.2ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 115/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_115.jpg: 768x1280 2 persons, 1053.9ms\n",
      "Speed: 1.5ms preprocess, 1053.9ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 116/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_116.jpg: 768x1280 2 persons, 1036.2ms\n",
      "Speed: 1.7ms preprocess, 1036.2ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 117/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_117.jpg: 768x1280 2 persons, 1024.1ms\n",
      "Speed: 1.6ms preprocess, 1024.1ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 118/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_118.jpg: 768x1280 2 persons, 1029.8ms\n",
      "Speed: 1.7ms preprocess, 1029.8ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 119/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_119.jpg: 768x1280 1 person, 1049.0ms\n",
      "Speed: 1.6ms preprocess, 1049.0ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 120/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_120.jpg: 768x1280 1 person, 1053.5ms\n",
      "Speed: 2.1ms preprocess, 1053.5ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 121/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_121.jpg: 768x1280 1 person, 1048.1ms\n",
      "Speed: 1.6ms preprocess, 1048.1ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 122/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_122.jpg: 768x1280 1 person, 1039.9ms\n",
      "Speed: 1.8ms preprocess, 1039.9ms inference, 0.8ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 123/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_123.jpg: 768x1280 1 person, 1065.6ms\n",
      "Speed: 1.9ms preprocess, 1065.6ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 124/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_124.jpg: 768x1280 1 person, 1043.1ms\n",
      "Speed: 1.6ms preprocess, 1043.1ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 125/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_125.jpg: 768x1280 1 person, 1050.9ms\n",
      "Speed: 2.2ms preprocess, 1050.9ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 126/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_126.jpg: 768x1280 1 person, 1027.8ms\n",
      "Speed: 1.6ms preprocess, 1027.8ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 127/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_127.jpg: 768x1280 1 person, 1031.3ms\n",
      "Speed: 1.6ms preprocess, 1031.3ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 128/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_128.jpg: 768x1280 1 person, 1027.5ms\n",
      "Speed: 1.6ms preprocess, 1027.5ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 129/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_129.jpg: 768x1280 1 person, 1028.5ms\n",
      "Speed: 1.7ms preprocess, 1028.5ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 130/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_130.jpg: 768x1280 1 person, 1026.1ms\n",
      "Speed: 2.0ms preprocess, 1026.1ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 131/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_131.jpg: 768x1280 1 person, 1027.5ms\n",
      "Speed: 2.1ms preprocess, 1027.5ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 132/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_132.jpg: 768x1280 1 person, 1025.1ms\n",
      "Speed: 1.6ms preprocess, 1025.1ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 133/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_133.jpg: 768x1280 1 person, 1028.2ms\n",
      "Speed: 2.0ms preprocess, 1028.2ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 134/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_134.jpg: 768x1280 1 person, 1030.2ms\n",
      "Speed: 1.5ms preprocess, 1030.2ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 135/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_135.jpg: 768x1280 1 person, 1024.4ms\n",
      "Speed: 2.1ms preprocess, 1024.4ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 136/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_136.jpg: 768x1280 1 person, 1041.1ms\n",
      "Speed: 1.7ms preprocess, 1041.1ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 137/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_137.jpg: 768x1280 1 person, 1029.4ms\n",
      "Speed: 1.7ms preprocess, 1029.4ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 138/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_138.jpg: 768x1280 1 person, 1033.2ms\n",
      "Speed: 1.5ms preprocess, 1033.2ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 139/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_139.jpg: 768x1280 1 person, 1027.8ms\n",
      "Speed: 1.8ms preprocess, 1027.8ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 140/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_140.jpg: 768x1280 1 person, 1030.6ms\n",
      "Speed: 1.6ms preprocess, 1030.6ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 141/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_141.jpg: 768x1280 1 person, 1024.5ms\n",
      "Speed: 1.8ms preprocess, 1024.5ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 142/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_142.jpg: 768x1280 1 person, 1023.6ms\n",
      "Speed: 1.8ms preprocess, 1023.6ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 143/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_143.jpg: 768x1280 1 person, 1049.8ms\n",
      "Speed: 1.8ms preprocess, 1049.8ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 144/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_144.jpg: 768x1280 1 person, 1055.6ms\n",
      "Speed: 1.6ms preprocess, 1055.6ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 145/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_145.jpg: 768x1280 1 person, 1043.1ms\n",
      "Speed: 1.7ms preprocess, 1043.1ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 146/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_146.jpg: 768x1280 1 person, 1031.1ms\n",
      "Speed: 1.6ms preprocess, 1031.1ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 147/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_147.jpg: 768x1280 1 person, 1039.2ms\n",
      "Speed: 1.6ms preprocess, 1039.2ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 148/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_148.jpg: 768x1280 1 person, 1042.9ms\n",
      "Speed: 1.8ms preprocess, 1042.9ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 149/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_149.jpg: 768x1280 (no detections), 1033.2ms\n",
      "Speed: 1.8ms preprocess, 1033.2ms inference, 0.3ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 150/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_150.jpg: 768x1280 1 person, 1041.3ms\n",
      "Speed: 1.5ms preprocess, 1041.3ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 151/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_151.jpg: 768x1280 1 person, 1043.3ms\n",
      "Speed: 1.7ms preprocess, 1043.3ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 152/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_152.jpg: 768x1280 1 person, 1023.7ms\n",
      "Speed: 1.7ms preprocess, 1023.7ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 153/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_153.jpg: 768x1280 1 person, 1046.8ms\n",
      "Speed: 1.8ms preprocess, 1046.8ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 154/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_154.jpg: 768x1280 1 person, 1044.6ms\n",
      "Speed: 1.8ms preprocess, 1044.6ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 155/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_155.jpg: 768x1280 1 person, 1032.0ms\n",
      "Speed: 1.7ms preprocess, 1032.0ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 156/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_156.jpg: 768x1280 1 person, 1049.6ms\n",
      "Speed: 2.1ms preprocess, 1049.6ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 157/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_157.jpg: 768x1280 1 person, 1043.3ms\n",
      "Speed: 1.5ms preprocess, 1043.3ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 158/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_158.jpg: 768x1280 1 person, 1048.7ms\n",
      "Speed: 1.9ms preprocess, 1048.7ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 159/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_159.jpg: 768x1280 1 person, 1035.4ms\n",
      "Speed: 1.6ms preprocess, 1035.4ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 160/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_160.jpg: 768x1280 1 person, 1039.2ms\n",
      "Speed: 1.8ms preprocess, 1039.2ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 161/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_161.jpg: 768x1280 1 person, 1043.1ms\n",
      "Speed: 1.6ms preprocess, 1043.1ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 162/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_162.jpg: 768x1280 1 person, 1054.8ms\n",
      "Speed: 1.8ms preprocess, 1054.8ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 163/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_163.jpg: 768x1280 1 person, 1038.3ms\n",
      "Speed: 1.8ms preprocess, 1038.3ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 164/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_164.jpg: 768x1280 1 person, 1039.0ms\n",
      "Speed: 1.7ms preprocess, 1039.0ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 165/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_165.jpg: 768x1280 1 person, 1040.9ms\n",
      "Speed: 1.7ms preprocess, 1040.9ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 166/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_166.jpg: 768x1280 1 person, 1040.0ms\n",
      "Speed: 1.6ms preprocess, 1040.0ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 167/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_167.jpg: 768x1280 1 person, 1063.6ms\n",
      "Speed: 1.6ms preprocess, 1063.6ms inference, 1.1ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 168/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_168.jpg: 768x1280 1 person, 1043.1ms\n",
      "Speed: 2.0ms preprocess, 1043.1ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 169/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_169.jpg: 768x1280 1 person, 1076.5ms\n",
      "Speed: 1.7ms preprocess, 1076.5ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 170/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_170.jpg: 768x1280 1 person, 1079.2ms\n",
      "Speed: 1.7ms preprocess, 1079.2ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 171/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_171.jpg: 768x1280 1 person, 1099.0ms\n",
      "Speed: 1.8ms preprocess, 1099.0ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 172/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_172.jpg: 768x1280 1 person, 1077.3ms\n",
      "Speed: 1.8ms preprocess, 1077.3ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 173/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_173.jpg: 768x1280 1 person, 1033.3ms\n",
      "Speed: 1.6ms preprocess, 1033.3ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 174/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_174.jpg: 768x1280 1 person, 1018.0ms\n",
      "Speed: 1.5ms preprocess, 1018.0ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 175/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_175.jpg: 768x1280 1 person, 1088.3ms\n",
      "Speed: 1.7ms preprocess, 1088.3ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 176/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_176.jpg: 768x1280 1 person, 1034.4ms\n",
      "Speed: 2.2ms preprocess, 1034.4ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 177/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_177.jpg: 768x1280 1 person, 1037.0ms\n",
      "Speed: 1.8ms preprocess, 1037.0ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 178/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_178.jpg: 768x1280 1 person, 1068.9ms\n",
      "Speed: 1.9ms preprocess, 1068.9ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 179/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_179.jpg: 768x1280 1 person, 1080.0ms\n",
      "Speed: 1.6ms preprocess, 1080.0ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 180/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_180.jpg: 768x1280 1 person, 1047.7ms\n",
      "Speed: 1.6ms preprocess, 1047.7ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 181/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_181.jpg: 768x1280 1 person, 1013.7ms\n",
      "Speed: 1.8ms preprocess, 1013.7ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 182/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_182.jpg: 768x1280 1 person, 1009.4ms\n",
      "Speed: 1.9ms preprocess, 1009.4ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 183/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_183.jpg: 768x1280 1 person, 1018.0ms\n",
      "Speed: 4.4ms preprocess, 1018.0ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 184/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_184.jpg: 768x1280 1 person, 1033.9ms\n",
      "Speed: 1.7ms preprocess, 1033.9ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 185/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_185.jpg: 768x1280 1 person, 1027.3ms\n",
      "Speed: 1.7ms preprocess, 1027.3ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 186/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_186.jpg: 768x1280 1 person, 1040.8ms\n",
      "Speed: 1.6ms preprocess, 1040.8ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 187/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_187.jpg: 768x1280 1 person, 1023.1ms\n",
      "Speed: 1.6ms preprocess, 1023.1ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 188/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_188.jpg: 768x1280 1 person, 1025.3ms\n",
      "Speed: 1.5ms preprocess, 1025.3ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 189/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_189.jpg: 768x1280 1 person, 1046.6ms\n",
      "Speed: 1.6ms preprocess, 1046.6ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 190/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_190.jpg: 768x1280 1 person, 1039.0ms\n",
      "Speed: 1.6ms preprocess, 1039.0ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 191/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_191.jpg: 768x1280 1 person, 1018.8ms\n",
      "Speed: 2.0ms preprocess, 1018.8ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 192/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_192.jpg: 768x1280 1 person, 1048.1ms\n",
      "Speed: 1.6ms preprocess, 1048.1ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 193/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_193.jpg: 768x1280 1 person, 1028.6ms\n",
      "Speed: 1.7ms preprocess, 1028.6ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 194/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_194.jpg: 768x1280 1 person, 1021.4ms\n",
      "Speed: 1.8ms preprocess, 1021.4ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 195/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_195.jpg: 768x1280 1 person, 1023.5ms\n",
      "Speed: 1.6ms preprocess, 1023.5ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 196/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_196.jpg: 768x1280 1 person, 1018.2ms\n",
      "Speed: 1.6ms preprocess, 1018.2ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 197/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_197.jpg: 768x1280 1 person, 1009.8ms\n",
      "Speed: 1.6ms preprocess, 1009.8ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 198/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_198.jpg: 768x1280 1 person, 1066.8ms\n",
      "Speed: 1.7ms preprocess, 1066.8ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 199/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_199.jpg: 768x1280 1 person, 1017.6ms\n",
      "Speed: 1.7ms preprocess, 1017.6ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 200/8087\n",
      "\n",
      "image 1/1 /Users/deniskrylov/Developer/PosEmotion/assets/frames/aJKL0ahn1Dk_200.jpg: 768x1280 2 persons, 1054.3ms\n",
      "Speed: 1.8ms preprocess, 1054.3ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1280)\n",
      "Progress: 201/8087\n"
     ]
    }
   ],
   "source": [
    "def apply_yolo():    \n",
    "    keypoints = []\n",
    "    model = YOLO(\"/Users/deniskrylov/Developer/PosEmotion/models/yolo-pose.pt\")\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            result = detect_poses(\"/Users/deniskrylov/Developer/PosEmotion/assets/frames/{}_{}.jpg\".format(\n",
    "                row[\"Video Tag\"], index), \n",
    "                model\n",
    "            )\n",
    "            keypoints.append(result.to_dict())\n",
    "            print(\"Progress: {}/{}\".format(index+1, len(df)))\n",
    "        except:\n",
    "            raise Exception(\"Error in detecting poses!\")\n",
    "\n",
    "    keypoints_df = pd.DataFrame(keypoints)\n",
    "    keypoints_df.to_csv(\"/Users/deniskrylov/Developer/PosEmotion/assets/annotations/yolo_keypoints.csv\", index=True)\n",
    "\n",
    "\n",
    "# Uncomment the line below to apply YOLO to the frames\n",
    "apply_yolo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OpenPose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DeepPose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize key points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization has 2 parts: per image and per segment.\n",
    "\n",
    "- [WRONG] Per Image: all keypoints will be normalized according to the default size of the image $(w,h)$ and according to the size of a person on the image.\n",
    "- Per Segment: all segment sizes will be normalized to the default segment size $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame-wise Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Clustering Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Poses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Emotion Label Association"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associate Poses with Emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluation and Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine Clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
